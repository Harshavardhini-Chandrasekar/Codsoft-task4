{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-01-27T09:34:44.510242Z","iopub.status.busy":"2024-01-27T09:34:44.509816Z","iopub.status.idle":"2024-01-27T09:34:44.583849Z","shell.execute_reply":"2024-01-27T09:34:44.582526Z","shell.execute_reply.started":"2024-01-27T09:34:44.51021Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>v1</th>\n","      <th>v2</th>\n","      <th>Unnamed: 2</th>\n","      <th>Unnamed: 3</th>\n","      <th>Unnamed: 4</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     v1                                                 v2 Unnamed: 2  \\\n","0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n","1   ham                      Ok lar... Joking wif u oni...        NaN   \n","2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n","3   ham  U dun say so early hor... U c already then say...        NaN   \n","4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n","\n","  Unnamed: 3 Unnamed: 4  \n","0        NaN        NaN  \n","1        NaN        NaN  \n","2        NaN        NaN  \n","3        NaN        NaN  \n","4        NaN        NaN  "]},"metadata":{},"output_type":"display_data"}],"source":["import pandas as pd\n","\n","spam_data = pd.read_csv('spam.csv',encoding = 'latin-1')\n","\n","display(spam_data.head())\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 5572 entries, 0 to 5571\n","Data columns (total 5 columns):\n"," #   Column      Non-Null Count  Dtype \n","---  ------      --------------  ----- \n"," 0   v1          5572 non-null   object\n"," 1   v2          5572 non-null   object\n"," 2   Unnamed: 2  50 non-null     object\n"," 3   Unnamed: 3  12 non-null     object\n"," 4   Unnamed: 4  6 non-null      object\n","dtypes: object(5)\n","memory usage: 217.8+ KB\n","None\n"]}],"source":["print(spam_data.info())"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-01-27T09:35:19.067865Z","iopub.status.busy":"2024-01-27T09:35:19.067487Z","iopub.status.idle":"2024-01-27T09:35:19.080365Z","shell.execute_reply":"2024-01-27T09:35:19.079084Z","shell.execute_reply.started":"2024-01-27T09:35:19.067835Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["     v1                                                 v2\n","0   ham  Go until jurong point, crazy.. Available only ...\n","1   ham                      Ok lar... Joking wif u oni...\n","2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n","3   ham  U dun say so early hor... U c already then say...\n","4   ham  Nah I don't think he goes to usf, he lives aro...\n"]}],"source":["spam_data_cleaned = spam_data.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'])\n","\n","print(spam_data_cleaned.head())"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-01-27T09:35:39.370737Z","iopub.status.busy":"2024-01-27T09:35:39.370344Z","iopub.status.idle":"2024-01-27T09:35:44.00627Z","shell.execute_reply":"2024-01-27T09:35:44.004909Z","shell.execute_reply.started":"2024-01-27T09:35:39.370708Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\Caxy\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Unzipping corpora\\stopwords.zip.\n"]},{"name":"stdout","output_type":"stream","text":["0    go jurong point crazi avail bugi n great world...\n","1                                ok lar joke wif u oni\n","2    free entri wkli comp win fa cup final tkt st m...\n","3                  u dun say earli hor u c alreadi say\n","4                 nah think goe usf live around though\n","Name: v2, dtype: object\n"]}],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","import re\n","import nltk\n","\n","nltk.download('stopwords')\n","\n","def clean_text(text):\n","    text = re.sub('[^a-zA-Z]', ' ', text)\n","    text = text.lower()\n","    stop_words = set(stopwords.words('english'))\n","    text = ' '.join([word for word in text.split() if word not in stop_words])\n","    stemmer = PorterStemmer()\n","    text = ' '.join([stemmer.stem(word) for word in text.split()])\n","    return text\n","\n","cleaned_texts = spam_data_cleaned['v2'].apply(clean_text)\n","\n","print(cleaned_texts.head())"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-01-27T09:36:17.541426Z","iopub.status.busy":"2024-01-27T09:36:17.540945Z","iopub.status.idle":"2024-01-27T09:36:17.684547Z","shell.execute_reply":"2024-01-27T09:36:17.683374Z","shell.execute_reply.started":"2024-01-27T09:36:17.54139Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training set shape: (4457, 6221)\n","Testing set shape: (1115, 6221)\n"]}],"source":["vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(cleaned_texts)\n","y = spam_data_cleaned['v1'].map({'ham': 0, 'spam': 1})  \n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print('Training set shape:', X_train.shape)\n","print('Testing set shape:', X_test.shape)"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-01-27T09:41:27.104227Z","iopub.status.busy":"2024-01-27T09:41:27.103804Z","iopub.status.idle":"2024-01-27T09:41:27.679726Z","shell.execute_reply":"2024-01-27T09:41:27.677647Z","shell.execute_reply.started":"2024-01-27T09:41:27.104195Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["SVM Accuracy: 0.9775784753363229\n","SVM Classification Report:\n","               precision    recall  f1-score   support\n","\n","         Ham       0.98      1.00      0.99       965\n","        Spam       0.98      0.85      0.91       150\n","\n","    accuracy                           0.98      1115\n","   macro avg       0.98      0.93      0.95      1115\n","weighted avg       0.98      0.98      0.98      1115\n","\n"]}],"source":["from sklearn.svm import SVC\n","\n","svm_model = SVC(kernel='linear', random_state=42)\n","svm_model.fit(X_train, y_train)\n","\n","y_pred_svm = svm_model.predict(X_test)\n","\n","accuracy_svm = accuracy_score(y_test, y_pred_svm)\n","\n","report_svm = classification_report(y_test, y_pred_svm, target_names=['Ham', 'Spam'])\n","\n","print('SVM Accuracy:', accuracy_svm)\n","print('SVM Classification Report:\\n', report_svm)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-01-27T09:47:05.702538Z","iopub.status.busy":"2024-01-27T09:47:05.702071Z","iopub.status.idle":"2024-01-27T09:48:01.682546Z","shell.execute_reply":"2024-01-27T09:48:01.681569Z","shell.execute_reply.started":"2024-01-27T09:47:05.702503Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From C:\\Users\\Caxy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n","WARNING:tensorflow:From C:\\Users\\Caxy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From C:\\Users\\Caxy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","Epoch 1/5\n","WARNING:tensorflow:From C:\\Users\\Caxy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n","\n","WARNING:tensorflow:From C:\\Users\\Caxy\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n","\n","63/63 [==============================] - 16s 165ms/step - loss: 0.2317 - accuracy: 0.9247 - val_loss: 0.1197 - val_accuracy: 0.9596\n","Epoch 2/5\n","63/63 [==============================] - 10s 152ms/step - loss: 0.0375 - accuracy: 0.9905 - val_loss: 0.0899 - val_accuracy: 0.9753\n","Epoch 3/5\n","63/63 [==============================] - 10s 162ms/step - loss: 0.0135 - accuracy: 0.9965 - val_loss: 0.1011 - val_accuracy: 0.9664\n","Epoch 4/5\n","63/63 [==============================] - 11s 173ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.1061 - val_accuracy: 0.9686\n","Epoch 5/5\n","63/63 [==============================] - 10s 159ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.1236 - val_accuracy: 0.9731\n","35/35 [==============================] - 1s 14ms/step - loss: 0.0600 - accuracy: 0.9812\n","RNN Model Accuracy: 0.9811659455299377\n"]}],"source":["from keras.models import Sequential\n","from keras.layers import Embedding, LSTM, Dense, Dropout\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.preprocessing.text import Tokenizer\n","from sklearn.preprocessing import LabelEncoder\n","import numpy as np\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(cleaned_texts)\n","sequences = tokenizer.texts_to_sequences(cleaned_texts)\n","\n","X = pad_sequences(sequences)\n","\n","le = LabelEncoder()\n","Y = le.fit_transform(y)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n","\n","model = Sequential()\n","model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=X.shape[1]))\n","model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n","\n","loss, accuracy = model.evaluate(X_test, y_test)\n","print('RNN Model Accuracy:', accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":483,"sourceId":982,"sourceType":"datasetVersion"}],"dockerImageVersionId":30635,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
